{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"j5dU7fcDL5zC"},"outputs":[],"source":["%pip install transformers datasets wandb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RshUalP2MANR"},"outputs":[],"source":["import os\n","from google.colab import drive\n","drive.mount(\"/content/drive\")\n","os.chdir(\"/content/drive/MyDrive/NLP_Project_1\")\n","os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n","\n","fine_tuned_model_name = \"to_delete\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"f8zgEuS5ax4B"},"outputs":[],"source":["!wandb login\n","\n","import wandb"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"fvVZ62CqMM4H"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'pandas'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-21c3babb527a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"]}],"source":["import pandas as pd\n","import torch\n","import datasets\n","import gc\n","import numpy as np\n","import re\n","import random\n","import utils\n","\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.nn import CrossEntropyLoss\n","from tqdm import tqdm\n","from collections import deque\n","from transformers import AutoTokenizer, DataCollatorWithPadding, AutoConfig,  Adafactor, get_cosine_schedule_with_warmup\n","from transformers import XLNetForSequenceClassification, BertForSequenceClassification, RobertaForSequenceClassification, AlbertForSequenceClassification\n","\n","SEED = 20220719\n","DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","BACKBONE_NAME = \"bert-base-uncased\"\n","\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","torch.manual_seed(SEED)\n","torch.cuda.manual_seed(SEED)\n","torch.cuda.manual_seed_all(SEED)\n","np.random.seed(SEED)\n","random.seed(SEED)\n","\n","tokenizer = AutoTokenizer.from_pretrained(BACKBONE_NAME)\n","tokenizer.add_tokens(\"_num_\")\n","\n","model_config = AutoConfig.from_pretrained(BACKBONE_NAME)\n","\n","torch.cuda.set_device(DEVICE)\n","print(DEVICE)"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":32766,"status":"ok","timestamp":1660910478659,"user":{"displayName":"박정민","userId":"11203274198292799302"},"user_tz":-540},"id":"7DGhEwg1EBUq"},"outputs":[],"source":["dataset = utils.load_data(\"./RawData\", 8, 22, tokenizer)\n","original_train = dataset[\"train\"]\n","original_valid = dataset[\"valid\"]\n","collator = DataCollatorWithPadding(tokenizer, return_tensors = \"pt\")"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":402,"status":"ok","timestamp":1660910528059,"user":{"displayName":"박정민","userId":"11203274198292799302"},"user_tz":-540},"id":"wyBkCPliClZN"},"outputs":[],"source":["def sweep_dataset(train, valid, collator, tokenizer, batch_size) :\n","    return utils.get_dataset(train, tokenizer, collator, batch_size, True), utils.get_dataset(valid, tokenizer, collator, batch_size, True)\n","\n","def sweep_optimizer(input_model, optimizer, learning_rate) :\n","    if optimizer == \"AdamW\" :\n","        optimizer = torch.optim.AdamW(input_model.parameters(), lr = learning_rate, eps = 1e-6, weight_decay = 0.02)\n","    elif optimizer == 'RMSprop' :\n","        optimizer = torch.optim.RMSprop(input_model.parameters(), lr = learning_rate, weight_decay = 0.02)\n","    return optimizer"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1660910529837,"user":{"displayName":"박정민","userId":"11203274198292799302"},"user_tz":-540},"id":"QcH_rWLIB11d"},"outputs":[],"source":["def create_model(backbone) :\n","    model = BertForSequenceClassification.from_pretrained(backbone, num_labels = 2, ignore_mismatched_sizes = True)\n","    model.resize_token_embeddings(len(tokenizer))\n","    model.train()\n","    return model"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":526,"status":"ok","timestamp":1660910530812,"user":{"displayName":"박정민","userId":"11203274198292799302"},"user_tz":-540},"id":"auYquF_xEIdt"},"outputs":[],"source":["def accuracy(pred, true) :\n","    pred = pred.softmax(1)\n","    pred = pred.argmax(1)\n","    return pred.eq(true).sum() / len(pred)\n","\n","def train_epoch(train_data, model, epoch, optimizer, device, lr_scheduler = None) :\n","    scaler = torch.cuda.amp.GradScaler()\n","\n","    loss_fn = torch.nn.CrossEntropyLoss(label_smoothing = 0.1)\n","\n","    cum_loss = deque(maxlen = 20)\n","    cum_acc = deque(maxlen = 20)\n","\n","    curr_loss = []\n","    curr_acc = []\n","\n","    model.train()\n","    with tqdm(train_data, unit = \" batch\") as tepoch :\n","        for i, batch in enumerate(tepoch) :\n","            tepoch.set_description(f\"Train Epoch\")\n","\n","            optimizer.zero_grad()\n","\n","            label = batch[\"labels\"].to(device)\n","            batch = {k : v.to(device) for k, v in batch.items()}\n","            \n","            with torch.cuda.amp.autocast() :\n","                outputs = model(**batch)\n","                loss = loss_fn(outputs['logits'], label)\n","\n","            logits = outputs[\"logits\"]\n","\n","            scaler.scale(loss).backward()\n","            scaler.step(optimizer)\n","            scaler.update()\n","            if lr_scheduler :\n","                lr_scheduler.step()\n","\n","            acc = accuracy(logits, label)\n","            cum_loss.append(float(loss))\n","            cum_acc.append(float(acc))\n","\n","            curr_loss.append(float(loss))\n","            curr_acc.append(float(acc))\n","\n","            tepoch.set_postfix(loss = sum(cum_loss) / len(cum_loss),\n","                               accuracy = sum(cum_acc) / len(cum_acc))\n","\n","            wandb.log({\"train_batch_loss\" : sum(cum_loss) / len(cum_loss),\n","                       \"train_batch_acc\" : sum(cum_acc) / len(cum_acc)},\n","                        step = i + (epoch * len(train_data)))\n","            \n","    return sum(curr_loss) / len(curr_loss), sum(curr_acc) / len(curr_acc)\n","\n","def valid_epoch(valid_data, model, epoch, device) :\n","    cum_loss = deque(maxlen = 20)\n","    cum_acc = deque(maxlen = 20)\n","\n","    curr_loss = []\n","    curr_acc = []\n","\n","    model.eval()\n","    with torch.no_grad() :\n","        with tqdm(valid_data, unit = \" batch\") as tepoch :\n","            for i, batch in enumerate(tepoch) :\n","                tepoch.set_description(f\"Valid Epoch\")\n","                label = batch[\"labels\"].to(device)\n","                batch = {k : v.to(device) for k, v in batch.items()}\n","                \n","                with torch.cuda.amp.autocast():\n","                    outputs = model(**batch)\n","\n","                loss = outputs[\"loss\"]\n","                logits = outputs[\"logits\"]\n","\n","                acc = accuracy(logits, label)\n","                \n","                cum_loss.append(float(loss))\n","                cum_acc.append(float(acc))\n","                curr_loss.append(float(loss))\n","                curr_acc.append(float(acc))\n","\n","                tepoch.set_postfix(loss = sum(cum_loss) / len(cum_loss), \n","                                   accuracy = sum(cum_acc) / len(cum_acc))\n","\n","                wandb.log({\"valid_batch_loss\" : sum(curr_loss) / len(curr_loss),\n","                           \"valid_batch_acc\" : sum(curr_acc) / len(curr_acc)},\n","                           step = i + (epoch * len(valid_data)))\n","            \n","    return sum(curr_loss) / len(curr_loss), sum(curr_acc) / len(curr_acc)"]},{"cell_type":"code","execution_count":34,"metadata":{"executionInfo":{"elapsed":392,"status":"ok","timestamp":1660910818625,"user":{"displayName":"박정민","userId":"11203274198292799302"},"user_tz":-540},"id":"GNVamPR_FPW0"},"outputs":[],"source":["def run_sweep(config = None):\n","    with wandb.init(config=config) :\n","        w_config = wandb.config\n","        \n","        train_data, valid_data = sweep_dataset(original_train, original_valid, collator, tokenizer, w_config.batch_size)\n","        model = create_model(BACKBONE_NAME).to(DEVICE)\n","        optimizer = sweep_optimizer(model, w_config.optimizer, w_config.learning_rate)\n","        lr_scheduler = get_cosine_schedule_with_warmup(optimizer = optimizer,\n","                                                       num_warmup_steps = int(len(train_data) * w_config.epochs * 0.06),\n","                                                       num_training_steps = len(train_data) * w_config.epochs)\n","        for epoch in range(w_config.epochs):\n","            train_loss, train_acc = train_epoch(train_data, model, epoch, optimizer, DEVICE, lr_scheduler)\n","            valid_loss, valid_acc = valid_epoch(valid_data, model, epoch, DEVICE)\n","            wandb.log({\"loss\": valid_loss})      "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6OGiVdB4eCK3"},"outputs":[],"source":["sweep_config = {\n","  \"name\" : \"bert_sweep\",\n","    'metric' : {\n","    'name': 'loss',\n","    'goal': 'minimize'   \n","    },\n","  \"method\" : \"random\",\n","  \"parameters\" : {\n","    'optimizer': {\n","        'values': ['AdamW', 'RMSprop']\n","    },\n","    \"epochs\" : {\n","      \"values\" : [3, 5]\n","    },\n","    \"learning_rate\" : {\n","        \"min\": 1e-7,\n","        \"max\": 1e-4\n","    },\n","    \"batch_size\" : {\n","        'values' : [64, 128, 256, 512]\n","    }\n","  }\n","}\n","\n","sweep_id = wandb.sweep(sweep_config, project = \"Goorm_1st_project\", entity = \"2nd_group\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g8sy3V6cXqGe"},"outputs":[],"source":["wandb.agent(sweep_id, run_sweep, count = 6)"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyP3grk8FrZLGDlkp6dvTBi4","collapsed_sections":[],"machine_shape":"hm","name":"sweep.ipynb","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3.6.9 ('project_1')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"vscode":{"interpreter":{"hash":"3ecd6fbaf527d4746845fc96b9b0282883af8a4830167910a71d2c478b38d88d"}}},"nbformat":4,"nbformat_minor":0}
